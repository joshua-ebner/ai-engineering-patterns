{"ts": 1770699617.1214879, "eval_id": "rag-eval-query-001", "query": "What is a retriever in LangChain?", "must_refuse": false, "refused": false, "passed": true, "expected_sources": ["retrieval.mdx"], "retrieved_sources": ["knowledge-base.mdx", "philosophy.mdx", "rag.mdx", "retrieval.mdx"], "hit": true, "latency_sec": 25.898947954177856, "http_status": 200}
{"ts": 1770699625.974698, "eval_id": "rag-eval-query-002", "query": "What is retrieval-augmented generation (RAG)?", "must_refuse": false, "refused": false, "passed": true, "expected_sources": ["rag.mdx", "retrieval.mdx"], "retrieved_sources": ["retrieval.mdx"], "hit": true, "latency_sec": 8.852057933807373, "http_status": 200}
{"ts": 1770699634.916327, "eval_id": "rag-eval-query-003", "query": "What is a vector store in LangChain?", "must_refuse": false, "refused": false, "passed": true, "expected_sources": ["knowledge-base.mdx", "rag.mdx"], "retrieved_sources": ["knowledge-base.mdx", "philosophy.mdx"], "hit": true, "latency_sec": 8.940925121307373, "http_status": 200}
{"ts": 1770699636.67371, "eval_id": "rag-eval-query-004", "query": "What are embeddings used for in RAG?", "must_refuse": false, "refused": false, "passed": true, "expected_sources": ["rag.mdx"], "retrieved_sources": ["rag.mdx", "retrieval.mdx"], "hit": true, "latency_sec": 1.7566637992858887, "http_status": 200}
{"ts": 1770699642.857666, "eval_id": "rag-eval-query-005", "query": "What is a TextSplitter in LangChain and why is it used?", "must_refuse": false, "refused": false, "passed": true, "expected_sources": ["rag.mdx"], "retrieved_sources": ["knowledge-base.mdx", "philosophy.mdx", "rag.mdx"], "hit": true, "latency_sec": 6.182663917541504, "http_status": 200}
{"ts": 1770699649.9193149, "eval_id": "rag-eval-query-006", "query": "Describe the basic steps of a RAG pipeline from documents to answers.", "must_refuse": false, "refused": false, "passed": true, "expected_sources": ["retrieval.mdx"], "retrieved_sources": ["rag.mdx", "retrieval.mdx"], "hit": true, "latency_sec": 7.060555696487427, "http_status": 200}
{"ts": 1770699653.255698, "eval_id": "rag-eval-query-007", "query": "What is a 2-step RAG architecture?", "must_refuse": false, "refused": false, "passed": true, "expected_sources": ["retrieval.mdx"], "retrieved_sources": ["retrieval.mdx"], "hit": true, "latency_sec": 3.3359432220458984, "http_status": 200}
{"ts": 1770699656.2884102, "eval_id": "rag-eval-query-008", "query": "How does a retriever interact with a vector store?", "must_refuse": false, "refused": false, "passed": false, "expected_sources": ["retrieval.mdx"], "retrieved_sources": ["knowledge-base.mdx"], "hit": false, "latency_sec": 3.031830072402954, "http_status": 200}
{"ts": 1770699658.881151, "eval_id": "rag-eval-query-009", "query": "What is a knowledge base in LangChain and how is it used?", "must_refuse": false, "refused": true, "passed": false, "expected_sources": ["knowledge-base.mdx"], "retrieved_sources": ["get-help.mdx", "install.mdx", "overview.mdx", "philosophy.mdx"], "hit": false, "latency_sec": 2.5920510292053223, "http_status": 200}
{"ts": 1770699661.563266, "eval_id": "rag-eval-query-010", "query": "What is long-term memory in LangChain?", "must_refuse": false, "refused": false, "passed": true, "expected_sources": ["long-term-memory.mdx"], "retrieved_sources": ["long-term-memory.mdx", "philosophy.mdx", "short-term-memory.mdx"], "hit": true, "latency_sec": 2.681478977203369, "http_status": 200}
{"ts": 1770699666.137185, "eval_id": "rag-eval-query-011", "query": "What is short-term memory in LangChain?", "must_refuse": false, "refused": false, "passed": true, "expected_sources": ["short-term-memory.mdx"], "retrieved_sources": ["long-term-memory.mdx", "philosophy.mdx", "short-term-memory.mdx"], "hit": true, "latency_sec": 4.5733160972595215, "http_status": 200}
{"ts": 1770699668.8515809, "eval_id": "rag-eval-query-012", "query": "How does LangChain support observability for LLM apps?", "must_refuse": false, "refused": false, "passed": false, "expected_sources": ["observability.mdx"], "retrieved_sources": ["knowledge-base.mdx", "overview.mdx", "philosophy.mdx"], "hit": false, "latency_sec": 2.7135000228881836, "http_status": 200}
{"ts": 1770699673.891267, "eval_id": "rag-eval-query-013", "query": "What is MCP in the LangChain ecosystem?", "must_refuse": false, "refused": false, "passed": true, "expected_sources": ["mcp.mdx"], "retrieved_sources": ["install.mdx", "mcp.mdx", "philosophy.mdx"], "hit": true, "latency_sec": 5.038740873336792, "http_status": 200}
{"ts": 1770699674.71019, "eval_id": "rag-eval-query-014", "query": "What is the best embedding model in 2026?", "must_refuse": true, "refused": true, "passed": true, "expected_sources": [], "retrieved_sources": [], "latency_sec": 0.8180811405181885, "http_status": 200}
{"ts": 1770699675.8296971, "eval_id": "rag-eval-query-015", "query": "Compare LangChain pricing tiers and plans.", "must_refuse": true, "refused": true, "passed": true, "expected_sources": [], "retrieved_sources": ["get-help.mdx", "install.mdx", "philosophy.mdx"], "latency_sec": 1.1184728145599365, "http_status": 200}
{"ts": 1770699677.453661, "eval_id": "rag-eval-query-016", "query": "What is the best vector store?", "must_refuse": true, "refused": true, "passed": true, "expected_sources": [], "retrieved_sources": ["knowledge-base.mdx"], "latency_sec": 1.623042106628418, "http_status": 200}
